{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XImG6txw1lJ-"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Wczytanie danych\n",
        "# Pobieramy publiczny zbiór danych California Housing, który zawiera informacje o cenach nieruchomości w Kalifornii.\n",
        "data = fetch_california_housing()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target  # Dodajemy kolumnę z cenami mieszkań (wartość docelowa)\n"
      ],
      "metadata": {
        "id": "GZeNZxai2LKz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Podział na zbiór treningowy i testowy\n",
        "# Dane dzielimy na 80% do treningu i 20% do testów, aby móc ocenić model na nieznanych danych.\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['target']), df['target'], test_size=0.2,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "aLxcsV8h2a4z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Skalowanie cech\n",
        "# Normalizujemy dane, aby poprawić efektywność algorytmów uczenia maszynowego.\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "k9mv113E3Xc5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Inicjalizacja modeli\n",
        "# Wybieramy dwa modele:\n",
        "# - Gradient Boosting: silny model boostingowy, dobrze radzący sobie na zbiorach danych o złożonych zależnościach.\n",
        "# - Random Forest: las losowy, który dobrze generalizuje, ale może wymagać większych zasobów obliczeniowych.\n",
        "models = {\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=500, learning_rate=0.1, max_depth=4, random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=500, max_depth=10, random_state=42, n_jobs=-1)\n",
        "}"
      ],
      "metadata": {
        "id": "-qW_3iyj3hN7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parametry:\n",
        "# - n_estimators: liczba drzew decyzyjnych w modelu (500 dla obu modeli).\n",
        "# - learning_rate (tylko dla Gradient Boosting): tempo uczenia (0.1).\n",
        "# - max_depth: maksymalna głębokość drzewa decyzyjnego (4 dla Gradient Boosting, 10 dla Random Forest).\n",
        "# - random_state: zapewnia powtarzalność wyników.\n",
        "# - n_jobs (-1 dla Random Forest): używa wszystkich dostępnych rdzeni procesora."
      ],
      "metadata": {
        "id": "bW_1oLbB4J0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Trenowanie i ewaluacja\n",
        "# Dla każdego modelu mierzymy czas trenowania i obliczamy błędy MAE oraz RMSE.\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    mae = mean_absolute_error(y_test, y_pred)  # Średni błąd bezwzględny\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Pierwiastek z błędu średniokwadratowego\n",
        "\n",
        "    results[name] = {\n",
        "        \"Train Time (s)\": train_time,\n",
        "        \"MAE\": mae,\n",
        "        \"RMSE\": rmse\n",
        "    }\n",
        "\n",
        "    joblib.dump(model, f\"{name}_model.pkl\")  # Zapisanie modelu do pliku"
      ],
      "metadata": {
        "id": "f7hZuT034F7q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Wyświetlenie wyników\n",
        "# Wyniki przedstawiamy w formie tabeli zawierającej czas trenowania oraz wartości błędów.\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWReEjZw6PNC",
        "outputId": "d1247d45-e460-46f7-f2db-cf57de643bbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Train Time (s)       MAE      RMSE\n",
            "Gradient Boosting       45.131116  0.308304  0.467761\n",
            "Random Forest           38.581659  0.365239  0.542726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7 predykcja na danych zewnetrznych\n",
        "sample_data = np.mean(X_test_scaled, axis=0).reshape(1,-1)  # Średnie wartości cech ze zbioru testowego\n",
        "sample_data_scaled = scaler.transform(sample_data)\n",
        "print(\"\\nPrzykladowe dane wejsciowe:\")\n",
        "print(sample_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD_HJzMs80Vn",
        "outputId": "69a00b59-60ed-4945-b4d9-a893797229ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Przykladowe dane wejsciowe:\n",
            "[[-0.02647585  0.01237949 -0.01305925 -0.00011079 -0.00429306 -0.01135997\n",
            "  -0.0264153   0.03137725]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.DataFrame(sample_data,columns=data.feature_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQD2iS0--g7t",
        "outputId": "30bea67d-2f1c-490b-e478-a6d21305adec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
            "0 -0.026476  0.012379 -0.013059  -0.000111   -0.004293  -0.01136 -0.026415   \n",
            "\n",
            "   Longitude  \n",
            "0   0.031377  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    prediction = model.predict(sample_data_scaled)\n",
        "    print(f\"\\nPredykcja dla modelu {name}: {prediction[0]:.2f} [setki tysięcy $]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5UN4EIQ-xCY",
        "outputId": "200be580-97b1-41eb-dcb9-f25e2d100aa8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predykcja dla modelu Gradient Boosting: 5.42 [setki tysięcy $]\n",
            "\n",
            "Predykcja dla modelu Random Forest: 1.73 [setki tysięcy $]\n"
          ]
        }
      ]
    }
  ]
}