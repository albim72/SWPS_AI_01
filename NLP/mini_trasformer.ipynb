{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cpdv7zVY2wz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mini Transformer - BUMBLEBEE - CEL: zbudować mały model jezykowy na self-attension z jedną warstwą transformera, która potrafi uczyć się prostych zależnosci w sekwencjach (przwidywanie następnego tokenu)"
      ],
      "metadata": {
        "id": "pSswmQvQfNA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "eclEMopZfqNy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KROK2: definiujemy poejdynczy blok transformera"
      ],
      "metadata": {
        "id": "T5n1LVLxf2VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.key = nn.Linear(embed_dim, embed_dim,bias=False)\n",
        "        self.query = nn.Linear(embed_dim, embed_dim,bias=False)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim,bias=False)\n",
        "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.ln = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    #KROK3: mechanizm self-attention\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape #B=batch, T=sequence length, C=embedding size\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        scores = q @ k.transpose(-2, -1) / (C**0.5) #B,T,T -> oblicza podobieństwo między tokenami!\n",
        "        mask = torch.tril(torch.ones(T,T)).to(x.device) #nie patrzymy na przyszłe tokeny - (ważne w modelach generatywnych)\n",
        "        scores = scores.masked_fill(mask == 0,float('-inf')) #maskowanie przyszłości\n",
        "\n",
        "        att = F.softmax(scores, dim=-1) #rozkład uwagi\n",
        "        out=att@v #mieszanie wartości zgodnie z uwagą , v to \"treść\" tokenu który bierzemy\n",
        "        return self.ln(self.proj(out) + x) #resztkowe połączenie i normalizacja\n",
        "\n"
      ],
      "metadata": {
        "id": "xp0QmM8bf8nM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KROK 4: budujemy minimodel - Mini Transformer"
      ],
      "metadata": {
        "id": "8H13_iS9jEuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim,block_size):\n",
        "        super(MiniTransformer, self).__init__()\n",
        "        self.token_emb= nn.Embedding(vocab_size, embed_dim) #zmienia ID tokenu na wektor(embedding)\n",
        "        self.pos_emb = nn.Embedding(block_size, embed_dim) #dodaje informację o kolejności tokenów\n",
        "        self.transformer = TransformerBlock(embed_dim) #jeden blok attention + LayerNorm\n",
        "        self.lm_head = nn.Linear(embed_dim, vocab_size) #przekształca wektor z powrotem na prawdopodobieństwo tokenów\n",
        "\n",
        "    #KROK5: forward - przetwarzanie sekwencji\n",
        "\n",
        "    def forward(self, idx):\n",
        "      B, T = idx.shape\n",
        "      token_embeddings = self.token_emb(idx) #(B,T,C)\n",
        "      position_embeddings = self.pos_emb(torch.arange(T).to(idx.device)) #(T,C)\n",
        "      x = token_embeddings + position_embeddings #(B,T,C) - dodwanie pozycji\n",
        "      x = self.transformer(x) #(B,T,C)\n",
        "      logits = self.lm_head(x) #(B,T,vocab_size) - -predykcja kolejnych tokenów\n",
        "      return logits\n",
        "\n",
        "    #model bierze sekwencję tokenów, przelicza ich znaczenie (token + pozycja), przetwarza przez mechanizm attention\n",
        "    #i na końcu mówi: jaki powinien być następny token"
      ],
      "metadata": {
        "id": "1mAnudlqjBKs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#użycie modelu\n",
        "model = MiniTransformer(vocab_size=20, embed_dim=32, block_size=8)\n",
        "example_input = torch.randint(0, 20, (1, 8))\n",
        "output = model(example_input)\n",
        "print(output.shape)\n",
        "print(f\"Input: {example_input}\")\n",
        "print(f\"Output: {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccTBDUBik3mA",
        "outputId": "f9d4b3ad-5fa9-4e86-88a1-4eceb187ab96"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 20])\n",
            "Input: tensor([[ 2, 18, 11, 18, 14, 11, 17, 16]])\n",
            "Output: tensor([[[ 3.7593e-01,  5.2333e-01,  8.2774e-01,  3.3304e-01,  5.6342e-01,\n",
            "          -1.4758e-01, -5.1432e-02, -1.2750e-01, -5.8661e-01,  7.7366e-01,\n",
            "           2.9653e-01,  7.3321e-01,  7.9648e-01, -1.5888e-01, -6.4371e-01,\n",
            "          -1.0302e-02, -4.6319e-01, -7.0561e-01, -2.6548e-01,  1.0039e-01],\n",
            "         [-6.8498e-01,  6.1105e-01,  1.2246e+00,  1.0107e-01,  2.2005e-01,\n",
            "           3.2313e-02,  6.6484e-01,  2.2130e-04, -1.7977e-01,  2.3000e-01,\n",
            "           6.7188e-01, -1.2369e-01, -2.2323e-01,  8.4430e-01, -1.0059e+00,\n",
            "           4.6596e-01, -3.0223e-01,  1.0519e-01, -3.5162e-01, -1.3727e+00],\n",
            "         [ 6.3291e-02,  5.9362e-01,  6.9861e-01, -2.4390e-02, -7.2545e-02,\n",
            "          -2.2119e-01, -2.8862e-02,  3.6147e-02,  3.2116e-02, -1.0930e+00,\n",
            "           3.0994e-01,  6.5896e-01,  9.1561e-01, -2.5862e-01, -1.5541e-01,\n",
            "           5.6020e-01, -6.4970e-01, -4.7901e-01, -5.4097e-01,  5.9125e-01],\n",
            "         [-3.0835e-01,  1.2359e+00,  2.4292e-01,  3.4066e-01,  2.0978e-01,\n",
            "           8.6965e-01,  6.2079e-01, -8.0438e-02, -8.4914e-01,  2.9175e-01,\n",
            "           1.3368e+00,  3.6901e-02, -9.3381e-01,  1.1101e-01, -8.9418e-01,\n",
            "           4.9039e-02, -6.2700e-01, -1.2937e-01, -5.6590e-01, -8.1940e-01],\n",
            "         [ 6.9938e-02, -7.2901e-01,  1.0714e+00, -1.8000e-01, -1.8281e-01,\n",
            "          -3.1073e-02, -1.9326e-01,  2.8344e-01, -1.0935e-02,  7.2939e-01,\n",
            "          -5.5571e-01, -4.6159e-01, -4.2935e-01, -1.0859e-01,  4.1764e-01,\n",
            "           7.3535e-03,  8.0156e-02, -3.3657e-01, -1.1787e+00,  1.5692e-01],\n",
            "         [ 1.3568e-01, -4.9512e-01,  1.2920e+00,  4.1271e-01, -4.5088e-01,\n",
            "          -5.1727e-01,  1.6583e-01,  1.1014e+00,  3.6545e-01, -4.7944e-01,\n",
            "          -9.6091e-02, -1.1663e-01,  3.8199e-01,  5.4705e-01,  7.3019e-01,\n",
            "           7.4840e-01, -1.5979e+00, -8.6872e-01,  9.6657e-02, -1.2550e-01],\n",
            "         [ 3.1656e-01, -7.3241e-02,  3.5845e-02,  5.1799e-01,  8.4857e-02,\n",
            "          -2.2982e-01, -6.6434e-02,  2.1564e-01,  3.1829e-02,  4.0444e-01,\n",
            "           5.4833e-01,  7.8177e-01,  8.6132e-01,  5.6275e-01, -1.2277e-01,\n",
            "          -9.8244e-01,  4.5304e-01,  7.5213e-03, -9.5932e-01, -6.5254e-01],\n",
            "         [ 4.3407e-01,  5.2817e-01,  5.8854e-01,  6.5206e-01, -4.4020e-01,\n",
            "           2.2365e-01, -6.9179e-02,  1.2588e+00, -4.8536e-01, -2.5054e-01,\n",
            "           1.4452e+00, -5.1557e-01,  3.4489e-01,  2.7428e-01,  1.0709e-01,\n",
            "          -9.0868e-01, -2.1589e-01,  1.6277e-01, -5.7667e-01, -1.1854e+00]]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    }
  ]
}