{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd5f8fdf",
   "metadata": {},
   "source": [
    "# Zadanie 4 – Analiza sentymentu tekstów użytkownika\n",
    "W tym zadaniu budujemy klasyfikator, który rozpoznaje czy wypowiedź użytkownika ma charakter pozytywny, negatywny czy neutralny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd47bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcee8de",
   "metadata": {},
   "source": [
    "## Dane wejściowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'text': [\n",
    "        'Ten produkt jest świetny, polecam każdemu!',\n",
    "        'To była najgorsza obsługa jaką kiedykolwiek miałem',\n",
    "        'Jestem zadowolony z zakupu',\n",
    "        'Nie polecam, bardzo słaba jakość',\n",
    "        'Obsługa była w porządku, ale bez rewelacji',\n",
    "        'Fantastyczne doświadczenie, wszystko poszło gładko',\n",
    "        'Nie mogę powiedzieć, żeby to było dobre',\n",
    "        'Zdecydowanie warto było!',\n",
    "        'Raczej przeciętnie, spodziewałem się więcej',\n",
    "        'Super, jestem bardzo zadowolony'\n",
    "    ],\n",
    "    'sentiment': [\n",
    "        'pozytywny', 'negatywny', 'pozytywny', 'negatywny', 'neutralny',\n",
    "        'pozytywny', 'negatywny', 'pozytywny', 'neutralny', 'pozytywny'\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed8baa6",
   "metadata": {},
   "source": [
    "## Tokenizacja i kodowanie etykiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6dd560",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=1000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "padded = pad_sequences(sequences, maxlen=10, padding='post')\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(df['sentiment'].unique())}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "labels = df['sentiment'].map(label2id).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ef02a8",
   "metadata": {},
   "source": [
    "## Budowa i trening modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=1000, output_dim=16, input_length=10),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(label2id), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516e9dc",
   "metadata": {},
   "source": [
    "## Predykcja nowych wypowiedzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196abcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    'To było niesamowite przeżycie',\n",
    "    'Jestem zawiedziony jakością produktu',\n",
    "    'Nic specjalnego, tak sobie',\n",
    "    'Obsługa klienta była wyjątkowa',\n",
    "    'Nie warto tych pieniędzy'\n",
    "]\n",
    "seq = tokenizer.texts_to_sequences(test_sentences)\n",
    "pad = pad_sequences(seq, maxlen=10, padding='post')\n",
    "preds = model.predict(pad)\n",
    "\n",
    "for i, p in enumerate(preds):\n",
    "    print(f'{test_sentences[i]} -> {id2label[np.argmax(p)]}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
