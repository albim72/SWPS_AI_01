{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udf10 Emergent Behavior Using TensorFlow\n", "\n", "This notebook simulates emergent behavior using a group of simple neural networks (agents) implemented in TensorFlow. \n", "Each agent adjusts its internal state based on the average state of the population. Over time, the system may exhibit convergence, oscillation, or clustering\u2014demonstrating **emergence**.\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "tf.random.set_seed(42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udde0 Define Agent Model\n", "Each agent is a simple neural network with a single dense layer that maps 3 inputs to 1 output."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["class Agent:\n", "    def __init__(self):\n", "        self.model = tf.keras.Sequential([\n", "            tf.keras.layers.Dense(1, input_shape=(3,), activation='tanh', use_bias=True)\n", "        ])\n", "        self.state = tf.Variable(tf.random.uniform([1], 0, 1))\n", "\n", "    def update(self, mean_state, all_states):\n", "        diff = mean_state - self.state\n", "        inputs = tf.stack([self.state, mean_state, diff], axis=-1)\n", "        delta = self.model(inputs)\n", "        self.state.assign_add(0.1 * delta)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd04 Simulation Parameters"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["NUM_AGENTS = 30\n", "STEPS = 100\n", "\n", "agents = [Agent() for _ in range(NUM_AGENTS)]\n", "history = []"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["for step in range(STEPS):\n", "    current_states = tf.stack([agent.state for agent in agents])\n", "    mean_state = tf.reduce_mean(current_states)\n", "    \n", "    for agent in agents:\n", "        agent.update(mean_state, current_states)\n", "    \n", "    history.append([agent.state.numpy()[0] for agent in agents])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcca Visualize Results"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["history = np.array(history)\n", "plt.figure(figsize=(12, 6))\n", "for i in range(NUM_AGENTS):\n", "    plt.plot(history[:, i], alpha=0.6, label=f\"Agent {i}\")\n", "plt.axhline(y=np.mean(history[-1]), color='r', linestyle='--', label='Final Mean')\n", "plt.title(\"Emergent Behavior of TensorFlow Agents\")\n", "plt.xlabel(\"Step\")\n", "plt.ylabel(\"State Value\")\n", "plt.grid(True)\n", "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')\n", "plt.tight_layout()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": ""}}, "nbformat": 4, "nbformat_minor": 2}